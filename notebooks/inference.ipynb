{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferring State Leakage Across Reset Gates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2022 Allen Mi, Shuwen Deng, and Jakub Szefer\n",
    "\n",
    "This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License along with this program. If not, see <https://www.gnu.org/licenses/>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Imports and Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.optimize import curve_fit, fsolve\n",
    "\n",
    "from qiskit import QuantumCircuit, transpile, execute\n",
    "\n",
    "import scripts.utils as u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load IBM Q Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider = u.load_provider('../credentials/provider.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify saved data and figures directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../experiments/inference/all_7q_6r_72c_2p'\n",
    "figures_dir = '../figures/inference/all_7q_6r_72c_2p'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify constants\n",
    "- Total number of qubits\n",
    "- Width of two-column figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_QUBITS = 7\n",
    "FIG_SINGLE_WIDTH = 714\n",
    "FIG_DOUBLE_WIDTH = 1500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify global variables\n",
    "- Maximum number of reset operations\n",
    "- Number of shots to be performed in experiments\n",
    "- Number of $\\theta$ samples in $[0, \\pi]$\n",
    "- Number of $\\varphi$ samples in $[0, 2\\pi)$\n",
    "- Number of experiment passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_N_RESETS = 6\n",
    "N_SHOTS = 8192\n",
    "N_THETA = 9\n",
    "N_PHI = 8\n",
    "N_PASSES = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify backend names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "be_name_list = ['ibm_perth', 'ibm_lagos', 'ibmq_jakarta']\n",
    "# be_name_list = ['ibm_perth', 'ibmq_jakarta']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify backend proper names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "be_proper_name_dict = {\n",
    "    'ibm_perth': 'Perth',\n",
    "    'ibm_lagos': 'Lagos',\n",
    "    'ibmq_jakarta': 'Jakarta'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Defining Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_config_list(n_theta, n_phi):\n",
    "    theta_arr = np.linspace(0, np.pi, n_theta, endpoint=True)\n",
    "    phi_arr = np.linspace(0, 2 * np.pi, n_phi, endpoint=False)\n",
    "\n",
    "    return list(product(theta_arr, phi_arr))\n",
    "\n",
    "\n",
    "def construct_circ(q, theta, phi, measure_first, reset_count):\n",
    "    c = QuantumCircuit(7, 2)\n",
    "    c.rx(theta, q)\n",
    "    c.rz(phi, q)\n",
    "    if measure_first:\n",
    "        c.measure(q, 0)\n",
    "    for _ in range(reset_count):\n",
    "        c.reset(q)\n",
    "    c.measure(q, 1)\n",
    "    \n",
    "    return c\n",
    "\n",
    "\n",
    "def make_circuit_dict(config_arr, max_n_resets, n_passes):\n",
    "    cd = {'meas': [], 'direct': []}\n",
    "\n",
    "    for q in range(7):\n",
    "        cd['meas'].append([])\n",
    "        cd['direct'].append([])\n",
    "        for r in range(max_n_resets + 1):\n",
    "            cd['meas'][q].append([\n",
    "                construct_circ(q, theta, phi, True, r)\n",
    "                for _, (theta, phi) in product(range(n_passes), config_arr)\n",
    "            ])\n",
    "            cd['direct'][q].append([\n",
    "                construct_circ(q, theta, phi, False, r)\n",
    "                for _, (theta, phi) in product(range(n_passes), config_arr)\n",
    "            ])\n",
    "\n",
    "    return cd\n",
    "\n",
    "\n",
    "exec = lambda c, be_name, shots: execute(\n",
    "    transpile(c, backend=provider.get_backend(be_name), optimization_level=0),\n",
    "    backend=provider.get_backend(be_name), optimization_level=0,\n",
    "    shots=shots\n",
    ")\n",
    "\n",
    "\n",
    "def make_all_jobs(circuit_dict, max_n_resets, n_shots):\n",
    "    all_jd = {}\n",
    "\n",
    "    for be_name in be_name_list:\n",
    "        jd = {'meas': [], 'direct': []}\n",
    "        for q in range(7):\n",
    "            jd['meas'].append([])\n",
    "            jd['direct'].append([])\n",
    "            for r in range(max_n_resets + 1):\n",
    "                jd['meas'][q].append(\n",
    "                    exec(circuit_dict['meas'][q][r], be_name, n_shots)\n",
    "                )\n",
    "                jd['direct'][q].append(\n",
    "                    exec(circuit_dict['direct'][q][r], be_name, n_shots)\n",
    "                )\n",
    "        all_jd[be_name] = jd\n",
    "    \n",
    "    return all_jd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Generating Configs and Running Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = make_config_list(N_THETA, N_PHI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuits = make_circuit_dict(configs, MAX_N_RESETS, N_PASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jobs = make_all_jobs(circuits, MAX_N_RESETS, N_SHOTS)\n",
    "# u.save(jobs, f'{data_dir}/jobs.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = u.load(f'{data_dir}/jobs.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = {be: jobs[be] for be in be_name_list}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - Defining Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts(job):\n",
    "    cnt = job.result().get_counts()\n",
    "    v1 = [r.get('01', 0) + r.get('11', 0) for r in cnt]\n",
    "    a1 = [r.get('10', 0) + r.get('11', 0) for r in cnt]\n",
    "    \n",
    "    return v1, a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_results(all_jobs, configs, max_n_resets, n_shots, n_passes):\n",
    "    pre = []\n",
    "    \n",
    "    for be_name, x in all_jobs.items():\n",
    "        for victim_op, y in x.items():\n",
    "            for i_q, z in enumerate(y):\n",
    "                for i_r, job in enumerate(z):\n",
    "                    v1, a1 = get_counts(job)\n",
    "                    pre.extend([[\n",
    "                        be_name, i_q,\n",
    "                        victim_op, i_r,\n",
    "                        theta, phi,\n",
    "                        i_pass,\n",
    "                        v1[i_c], v1[i_c] / n_shots,\n",
    "                        a1[i_c], a1[i_c] / n_shots\n",
    "                    ] for i_c, (i_pass, (theta, phi)) in enumerate(\n",
    "                        product(range(n_passes), configs)\n",
    "                    )])\n",
    "    \n",
    "    return pd.DataFrame(\n",
    "        pre,\n",
    "        columns=[\n",
    "            'backend', 'qubit',\n",
    "            'victim_op', 'n_resets',\n",
    "            'theta', 'phi',\n",
    "            'i_pass',\n",
    "            'victim_count', 'victim_frequency',\n",
    "            'attacker_count', 'attacker_frequency'\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_results(results, be_name, qubit, n_resets, i_pass, measure_first):\n",
    "    if measure_first:\n",
    "        victim_op = 'meas'\n",
    "    else:\n",
    "        victim_op = 'direct'\n",
    "        \n",
    "    return results[\n",
    "        (results['backend'] == be_name) &\n",
    "        (results['qubit'] == qubit) &\n",
    "        (results['n_resets'] == n_resets) &\n",
    "        (results['victim_op'] == victim_op) &\n",
    "        (results['i_pass'] == i_pass)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse(func):\n",
    "    l = func(0)\n",
    "    r = func(np.pi)\n",
    "    \n",
    "    if l >= r:\n",
    "        top = l\n",
    "        bottom = r\n",
    "        bias = 0\n",
    "    else:\n",
    "        top = r\n",
    "        bottom = l\n",
    "        bias = np.pi\n",
    "    \n",
    "    def inverse_single(y):\n",
    "        if y >= top:\n",
    "            return bias\n",
    "        elif y < bottom:\n",
    "            return np.pi - bias\n",
    "        else:\n",
    "            return fsolve(lambda theta: func(theta) - y, np.pi / 2)\n",
    "    \n",
    "    def inverse_vectorized(y):\n",
    "        out = np.vectorize(inverse_single)(y)\n",
    "\n",
    "        if out.size == 1:\n",
    "            return out.item()\n",
    "        else:\n",
    "            return out\n",
    "    \n",
    "    return inverse_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(theta, a, b, c):\n",
    "    return a * (b * np.sin(theta / 2) ** 2 + (1 - b) / np.pi * theta) + c\n",
    "\n",
    "\n",
    "def rmspe(y_true, y_pred):\n",
    "    return np.sqrt((((y_true - y_pred) / y_true) ** 2).mean())\n",
    "\n",
    "\n",
    "def fit_snr(fit, data, axis=1, ddof=0, to_dB=True):\n",
    "    data = np.asanyarray(data)\n",
    "    sd = data.std(axis=axis, ddof=ddof)\n",
    "    m_snr = np.where(sd == 0, 0, abs(fit[0][0]) / sd).mean()\n",
    "    \n",
    "    if to_dB:\n",
    "        return 20 * np.log10(m_snr)\n",
    "    else:\n",
    "        return m_snr\n",
    "\n",
    "\n",
    "def fit_sigmoid(\n",
    "    results, be_name, qubit, n_resets, i_pass, measure_first,\n",
    "    y='attacker_frequency'\n",
    "):\n",
    "    x='theta'\n",
    "    res = select_results(results, be_name, qubit, n_resets, i_pass, measure_first)\n",
    "    fit =  curve_fit(\n",
    "        sigmoid, res[x], res[y],\n",
    "        bounds=((-1, 0, 0), (1, 1, 1))\n",
    "    )\n",
    "    func = lambda theta: sigmoid(theta, *fit[0])\n",
    "    inv = inverse(func)\n",
    "    \n",
    "    return fit, func, inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(\n",
    "    results, be_name, qubit, n_resets, i_pass_train, i_pass_test, measure_first,\n",
    "    y='attacker_frequency'\n",
    "):\n",
    "    x='theta'\n",
    "    thetas = results[x].unique()\n",
    "    n_thetas = len(thetas)\n",
    "    n_phis = len(results['phi'].unique())\n",
    "    \n",
    "    fit, func, inv = fit_sigmoid(\n",
    "        results, be_name, qubit, n_resets, i_pass_train, measure_first,\n",
    "        y=y\n",
    "    )\n",
    "    \n",
    "    res_train = select_results(results, be_name, qubit, n_resets, i_pass_train, measure_first)\n",
    "    res_test = select_results(results, be_name, qubit, n_resets, i_pass_test, measure_first)\n",
    "    \n",
    "    mat_train = res_train[y].to_numpy().reshape(n_thetas, n_phis)\n",
    "    mat_test = res_test[y].to_numpy().reshape(n_thetas, n_phis)\n",
    "    \n",
    "    rmspe_train = rmspe(res_train[y], func(res_train[x]))\n",
    "    rmspe_test = rmspe(res_test[y], func(res_test[x]))\n",
    "    \n",
    "    snr_train = fit_snr(fit, mat_train)\n",
    "    snr_test = fit_snr(fit, mat_test)\n",
    "    \n",
    "    acc_train = []\n",
    "    acc_test = []\n",
    "    \n",
    "    loss_train = np.zeros(n_thetas)\n",
    "    loss_test = np.zeros(n_thetas)\n",
    "    \n",
    "    for mat, acc, loss in [\n",
    "        (mat_train, acc_train, loss_train),\n",
    "        (mat_test, acc_test, loss_test)\n",
    "    ]: \n",
    "        for i, r in enumerate(mat):\n",
    "            theta_true = thetas[i]\n",
    "            for y_val in r:\n",
    "                theta_pred = inv(y_val)\n",
    "                loss[i] += (theta_true - theta_pred) ** 2\n",
    "                if i in [0, n_thetas - 1]:\n",
    "                    bin_true = (i == 0)\n",
    "                    bin_pred = (theta_pred <= 0.5 * np.pi)\n",
    "                    acc.append(bin_pred == bin_true)\n",
    "    \n",
    "    acc_train = np.sum(acc_train) / len(acc_train)\n",
    "    acc_test = np.sum(acc_test) / len(acc_test)\n",
    "    \n",
    "    loss_train = np.sqrt(loss_train / n_phis)\n",
    "    loss_test = np.sqrt(loss_test / n_phis)\n",
    "    \n",
    "    return (\n",
    "        (fit, func, inv),\n",
    "        (rmspe_train, rmspe_test),\n",
    "        (snr_train, snr_test),\n",
    "        (acc_train, acc_test),\n",
    "        (loss_train, loss_test)\n",
    "    )\n",
    "\n",
    "\n",
    "def summarize_metrics(\n",
    "    results, be_name, measure_first,\n",
    "    i_pass_train=1, i_pass_test=0,\n",
    "    y='attacker_frequency'\n",
    "):\n",
    "    snr_data = []\n",
    "    acc_data = []\n",
    "    loss_data = []\n",
    "    \n",
    "    for qubit, n_resets in product(range(N_QUBITS), results['n_resets'].unique()):\n",
    "        _, _, snr, acc, loss = compute_metrics(\n",
    "            results, be_name, qubit, n_resets, i_pass_train, i_pass_test, measure_first,\n",
    "            y=y\n",
    "        )\n",
    "        \n",
    "        snr_data.append([qubit, n_resets, 'a_train', snr[0]])\n",
    "        snr_data.append([qubit, n_resets, 'b_test', snr[1]])\n",
    "        \n",
    "        acc_data.append([qubit, n_resets, 'a_train', acc[0]])\n",
    "        acc_data.append([qubit, n_resets, 'b_test', acc[1]])\n",
    "                        \n",
    "        for i, theta in enumerate(results['theta'].unique()):\n",
    "            loss_data.append([\n",
    "                qubit, n_resets, theta, 'a_train', loss[0][i]\n",
    "            ])\n",
    "            loss_data.append([\n",
    "                qubit, n_resets, theta, 'b_test', loss[1][i]\n",
    "            ])\n",
    "        \n",
    "    snr_df = pd.DataFrame(\n",
    "        snr_data,\n",
    "        columns=[\n",
    "            'qubit', 'n_resets', 'category', 'snr'\n",
    "        ]\n",
    "    )\n",
    "    acc_df = pd.DataFrame(\n",
    "        acc_data,\n",
    "        columns=[\n",
    "            'qubit', 'n_resets', 'category', 'acc'\n",
    "        ]\n",
    "    )\n",
    "    loss_df = pd.DataFrame(\n",
    "        loss_data,\n",
    "        columns=[\n",
    "            'qubit', 'n_resets', 'theta', 'category', 'loss'\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return snr_df, acc_df, loss_df\n",
    "\n",
    "\n",
    "def mean_acc(\n",
    "    results, be_name, measure_first, exclude_qubits=[]\n",
    "):\n",
    "    acc_df = summarize_metrics(results, be_name, measure_first)[1]\n",
    "    sub_df = acc_df[\n",
    "        (~acc_df['qubit'].isin(exclude_qubits))\n",
    "    ]\n",
    "    return sub_df.groupby(['n_resets', 'category'], as_index=False)['acc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_freq(results, be_proper_name_dict, be_name, i_pass, measure_first, qubit_range=range(N_QUBITS)):\n",
    "    max_n_resets = results['n_resets'].max()\n",
    "    \n",
    "    fig_rows = len(qubit_range)\n",
    "    fig_cols = int(max_n_resets + 2)\n",
    "    \n",
    "    xs = np.linspace(0, np.pi, 1000)\n",
    "    fig_list = []\n",
    "    curve_list = []\n",
    "    \n",
    "    for qubit in qubit_range:\n",
    "        if measure_first:\n",
    "            y_victim = 'victim_frequency'\n",
    "            color_kwargs = {}\n",
    "        else:\n",
    "            y_victim = 'attacker_frequency'\n",
    "            color_kwargs = dict(color_discrete_sequence=['#ef553b'])\n",
    "            \n",
    "        fig_list.append(\n",
    "            px.box(\n",
    "                select_results(results, be_name, qubit, 0, i_pass, measure_first),\n",
    "                x='theta', y=y_victim, **color_kwargs\n",
    "            )\n",
    "        )\n",
    "\n",
    "        fig_list.extend([\n",
    "            px.box(\n",
    "                select_results(results, be_name, qubit, n_resets, i_pass, measure_first),\n",
    "                x='theta', y='attacker_frequency'\n",
    "            ) for n_resets in results['n_resets'].unique()\n",
    "        ])\n",
    "        \n",
    "        curve_list.append(\n",
    "            px.line(\n",
    "                x=xs,\n",
    "                y=fit_sigmoid(\n",
    "                    results, be_name, qubit, 0, i_pass, measure_first, y=y_victim\n",
    "                )[1](xs)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        curve_list.extend([\n",
    "            px.line(\n",
    "                x=xs,\n",
    "                y=fit_sigmoid(\n",
    "                    results, be_name, qubit, n_resets, i_pass, measure_first, y='attacker_frequency'\n",
    "                )[1](xs)\n",
    "            ) for n_resets in results['n_resets'].unique()\n",
    "        ])\n",
    "        \n",
    "    \n",
    "    for i, fig_sub in enumerate(fig_list):\n",
    "        fig_sub.data[0]['boxmean'] = True\n",
    "    \n",
    "    for i, curve_sub in enumerate(curve_list):\n",
    "        curve_sub.update_traces(\n",
    "            line_color=fig_list[i].data[0]['marker']['color'],\n",
    "            opacity=0.75\n",
    "        )\n",
    "    x_titles=['Victim'] + [\n",
    "        f'{i_reset} Resets' for i_reset in range(max_n_resets + 1)\n",
    "    ]\n",
    "    y_titles=[\n",
    "        f'Qubit {qubit}' for qubit in range(N_QUBITS)\n",
    "    ]\n",
    "    fig = make_subplots(\n",
    "        rows=fig_rows, cols=fig_cols,\n",
    "        x_title='Rotation Angle θ',\n",
    "        y_title='1-Output Frequency',\n",
    "        horizontal_spacing=0.024,\n",
    "        vertical_spacing=0.01,\n",
    "        shared_xaxes=True,\n",
    "        column_titles=x_titles,\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        margin=dict(l=60, r=0, t=55, b=55, pad=0),\n",
    "        height=55 * 2 + fig_rows * 120,\n",
    "        title_text='Qubit State Retention - '\n",
    "            f'{be_proper_name_dict[be_name]}, '\n",
    "            f'{\"With\" if measure_first else \"Without\"} Victim Measurement, Pass {i_pass}',\n",
    "        title_y=0.99\n",
    "    )\n",
    "    for r in range(fig_rows):\n",
    "        fig.update_yaxes(title_text=y_titles[r], title_standoff=0, row=r + 1, col=1)\n",
    "        for c in range(fig_cols):\n",
    "            fig.update_xaxes(\n",
    "                tickmode = 'array',\n",
    "                tickvals = [0, np.pi / 4, np.pi / 2, np.pi * 3 / 4, np.pi],\n",
    "                ticktext = ['0', 'π/4', 'π/2', '3π/4', 'π'],\n",
    "                row=r + 1, col=c + 1\n",
    "    \n",
    "            )\n",
    "    \n",
    "    for i, f in enumerate(fig_list):\n",
    "        fig.add_trace(\n",
    "            f.data[0], row=i // fig_cols + 1, col=i % fig_cols + 1\n",
    "        )\n",
    "    \n",
    "    for i, f in enumerate(curve_list):\n",
    "        fig.add_trace(\n",
    "            f.data[0], row=i // fig_cols + 1, col=i % fig_cols + 1\n",
    "        )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(\n",
    "    results, be_name, measure_first,\n",
    "    i_pass_train=1, i_pass_test=0,\n",
    "    y='attacker_frequency'\n",
    "): \n",
    "    fig_rows = 3\n",
    "    fig_cols = N_QUBITS\n",
    "    \n",
    "    snr_df, acc_df, loss_df = summarize_metrics(\n",
    "        results, be_name, measure_first,\n",
    "        i_pass_train=i_pass_train, i_pass_test=i_pass_test,\n",
    "        y=y\n",
    "    )\n",
    "    x_titles=[\n",
    "        f'Qubit {qubit}' for qubit in range(N_QUBITS)\n",
    "    ]\n",
    "    y_titles=['SNR (dB)', 'Binary Accuracy', 'Prediction Loss']\n",
    "    fig = make_subplots(\n",
    "        rows=fig_rows, cols=fig_cols,\n",
    "        x_title='Number of Reset Operations',\n",
    "        horizontal_spacing=0.01,\n",
    "        vertical_spacing=0.03,\n",
    "        shared_xaxes=True,\n",
    "        shared_yaxes=True,\n",
    "        column_titles=x_titles\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        margin=dict(l=0, r=0, t=55, b=55, pad=0),\n",
    "        height=55 * 2 + fig_rows * 120,\n",
    "        title_text='Performance Metrics - '\n",
    "            f'{be_proper_name_dict[be_name]}, '\n",
    "            f'{\"With\" if measure_first else \"Without\"} Victim Measurement',\n",
    "        title_y=0.98,\n",
    "        boxmode='group',\n",
    "        showlegend=False\n",
    "    )\n",
    "    fig.update_xaxes(\n",
    "        showgrid=True, zeroline=False\n",
    "    )\n",
    "    for r in range(fig_rows):\n",
    "        fig.update_yaxes(\n",
    "            title_text=y_titles[r], title_standoff=17,\n",
    "            row=r + 1, col=1\n",
    "        )\n",
    "    \n",
    "    for qubit in range(N_QUBITS):\n",
    "        fig.add_traces(\n",
    "            px.line(\n",
    "                snr_df[snr_df['qubit'] == qubit],\n",
    "                x='n_resets', y='snr', color='category',\n",
    "            ).data,\n",
    "            rows=[1] * 2, cols=[qubit + 1] * 2\n",
    "        )\n",
    "        fig.add_traces(\n",
    "            px.box(\n",
    "                loss_df[loss_df['qubit'] == qubit],\n",
    "                x='n_resets', y='loss', color='category',\n",
    "            ).data,\n",
    "            rows=[3] * 2, cols=[qubit + 1] * 2\n",
    "        )\n",
    "        fig.add_traces(\n",
    "            px.line(\n",
    "                acc_df[acc_df['qubit'] == qubit],\n",
    "                x='n_resets', y='acc', color='category',\n",
    "            ).data,\n",
    "            rows=[2] * 2, cols=[qubit + 1] * 2\n",
    "        )\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acc(results):\n",
    "    panels = [\n",
    "        ('ibmq_jakarta', True, []),\n",
    "        ('ibmq_jakarta', False, []),\n",
    "        ('ibm_lagos', True, []),\n",
    "        ('ibm_lagos', False, []),\n",
    "        ('ibm_perth', False, [1])\n",
    "    ]\n",
    "    fig_rows = 2\n",
    "    fig_cols = 3\n",
    "    \n",
    "    data = [mean_acc(results, *panel) for panel in panels]\n",
    "    \n",
    "    mean = data[-1].copy()\n",
    "    mean['acc'] = 0\n",
    "    for d in data:\n",
    "        mean['acc'] += d['acc']\n",
    "    mean['acc'] /= len(data)\n",
    "    data.append(mean)\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=fig_rows, cols=fig_cols,\n",
    "        x_title='Number of Reset Operations',\n",
    "        horizontal_spacing=0.01,\n",
    "        vertical_spacing=0.1,\n",
    "        shared_xaxes=True,\n",
    "        shared_yaxes=True,\n",
    "        subplot_titles=[\n",
    "            f'{be_proper_name_dict[be_name]}, '\n",
    "            f'{\"With\" if measure_first else \"Without\"} Victim Meas.'\n",
    "            for be_name, measure_first, _ in panels\n",
    "        ] + ['Mean']\n",
    "    )\n",
    "    fig.update_yaxes(range=[0.45, 1.05])\n",
    "    fig.update_layout(\n",
    "        margin=dict(l=0, r=0, t=55, b=55, pad=0),\n",
    "        height=55 * 2 + fig_rows * 180,\n",
    "        title_text='Binary Prediction Accuracy',\n",
    "        title_y=0.98,\n",
    "        showlegend=False\n",
    "    )\n",
    "    for i, d in enumerate(data):\n",
    "        fig.add_traces(\n",
    "            px.line(\n",
    "                d, x='n_resets', y='acc', color='category'\n",
    "            ).data,\n",
    "            rows=[i % fig_rows + 1] * 2, cols=[i // fig_rows + 1] * 2\n",
    "        )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Obtaining Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = make_results(jobs, configs, MAX_N_RESETS, N_SHOTS, N_PASSES)\n",
    "# u.save(results, f'{data_dir}/results.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = u.load(f'{data_dir}/results.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 - Plotting Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_freq(results, be_proper_name_dict, 'ibmq_jakarta', 0, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for be_name in be_name_list:\n",
    "    for victim_op in results['victim_op'].unique():\n",
    "        measure_first = (victim_op == 'meas')\n",
    "        \n",
    "        for i_pass in range(N_PASSES):\n",
    "            fig = plot_freq(results, be_proper_name_dict, be_name, i_pass, measure_first)\n",
    "            fig.write_image(f'{figures_dir}/freq/{be_name}_{victim_op}_p{i_pass}.pdf', width=FIG_DOUBLE_WIDTH)\n",
    "            \n",
    "            for qubit in range(N_QUBITS):\n",
    "                fig = plot_freq(\n",
    "                    results, be_proper_name_dict, be_name, i_pass, measure_first,\n",
    "                    qubit_range=[qubit]\n",
    "                )\n",
    "                fig.write_image(f'{figures_dir}/freq/{be_name}_{victim_op}_p{i_pass}_q{qubit}.pdf', width=FIG_DOUBLE_WIDTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(results, 'ibmq_jakarta', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for be_name in be_name_list:\n",
    "    for victim_op in results['victim_op'].unique():\n",
    "        measure_first = (victim_op == 'meas')\n",
    "        \n",
    "        fig = plot_metrics(results, be_name, measure_first)\n",
    "        fig.write_image(f'{figures_dir}/metrics/{be_name}_{victim_op}.pdf', width=FIG_DOUBLE_WIDTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_acc(results)\n",
    "fig.write_image(f'{figures_dir}/acc/acc.pdf', width=FIG_SINGLE_WIDTH)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b48b20d10b3aefbd7cd71500cd0fd70072d2233180efcae0efdada250f162269"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
